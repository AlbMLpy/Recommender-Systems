{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from polara.datasets.movielens import get_movielens_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seed, rand_seed = 0, 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load row Data file\n",
    "\n",
    "DATA_NAME = 'ml-1m'\n",
    "DATA_FILE = 'D:/datasets/recsys/movielens/{}.zip'.format(DATA_NAME)\n",
    "\n",
    "ml_data = get_movielens_data(local_file=DATA_FILE, get_genres=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode users and items to [0, N] interval with no missing indices\n",
    "useridx, all_users = pd.factorize(ml_data.userid)\n",
    "itemidx, all_items = pd.factorize(ml_data.movieid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings = csr_matrix( # for efficient storage and some computations\n",
    "    (\n",
    "        ml_data.rating.values,\n",
    "        (useridx, itemidx)\n",
    "    )\n",
    ")\n",
    "all_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(matrix, seed=None):\n",
    "    '''\n",
    "    Uses CSR format to efficiently access non-zero elements.\n",
    "    Can be easily wrapped by numba jit with minor changes.\n",
    "    '''\n",
    "    test_items = []\n",
    "    indptr = matrix.indptr\n",
    "    indices = matrix.indices\n",
    "    data = matrix.data\n",
    "    np.random.seed(seed) # control randomization\n",
    "    for i in range(len(indptr)-1): # for every user i\n",
    "        head = indptr[i]\n",
    "        tail = indptr[i+1]\n",
    "        vals = data[head:tail] # user ratings\n",
    "        pos_max, = np.where(vals == vals.max())\n",
    "        top_items = indices[head + pos_max] # top-rated items for user i\n",
    "        test_items.append(np.random.choice(top_items)) # sample of top-rated\n",
    "    return np.array(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = test_split(all_ratings, seed=split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = all_ratings.copy() # avoid mutating original data\n",
    "train_matrix[np.arange(len(test_items)), test_items] = 0 # exclude test items\n",
    "train_matrix.eliminate_zeros()\n",
    "train_matrix = (train_matrix > 0).astype('f8') # make data implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 50\n",
    "_, s, vh = svds(train_matrix, k=rank, return_singular_vectors='vh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50,), (50, 3706))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape, vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s[::-1] # sort in decreasing order of singular values\n",
    "item_factors = np.ascontiguousarray(vh[::-1, :].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_unseen(pool_size, sample_size, exclude):\n",
    "    '''Efficient sampling from a range with exclusion'''\n",
    "    assert (pool_size-len(exclude)) >= sample_size \n",
    "    src = np.random.rand(pool_size)\n",
    "    np.put(src, exclude, -1) # will never get to the top\n",
    "    return np.argpartition(src, -sample_size)[-sample_size:]\n",
    "\n",
    "def topk_idx(arr, topk, unsorted=False):\n",
    "    'Select top-k elements. Sort for raniking metrics.'\n",
    "    top_unsorted = np.argpartition(arr, -topk)[-topk:]\n",
    "    if unsorted:\n",
    "        return top_unsorted\n",
    "    return top_unsorted[np.argsort(-arr[top_unsorted])]\n",
    "\n",
    "\n",
    "def evaluate(observations, holdout, item_factors,\n",
    "             rand_size=999, topk=10, seed=None):\n",
    "    '''\n",
    "    Calculate Hit-Rate@topk with randomly sampled unseen items.\n",
    "    For further speedups can be wrapped by numba jit with minor changes.\n",
    "    Assumes only one test item per user.\n",
    "    '''\n",
    "    user_factors = observations.dot(item_factors)\n",
    "    n_users, n_items = train_matrix.shape\n",
    "    indptr = observations.indptr\n",
    "    indices = observations.indices\n",
    "    \n",
    "    hr = 0\n",
    "    arhr = 0\n",
    "    np.random.seed(seed) # control randomization\n",
    "    for i in range(len(indptr)-1):\n",
    "        head = indptr[i]\n",
    "        tail = indptr[i+1]\n",
    "        \n",
    "        seen_items = np.concatenate(([holdout[i]], indices[head:tail]))\n",
    "        rand_items = sample_unseen(n_items, rand_size, seen_items)\n",
    "        \n",
    "        holdout_prediction = item_factors[holdout[i], :] @ user_factors[i, :]\n",
    "        random_predictions = item_factors[rand_items, :] @ user_factors[i, :]\n",
    "        # test item goes first for simpler calculations:\n",
    "        merged_predictions = np.concatenate(([holdout_prediction], random_predictions))\n",
    "        \n",
    "        top_recs = topk_idx(merged_predictions, topk)\n",
    "        rec_pos, = np.where(top_recs == 0) # holdout item has index 0 (it was the first)\n",
    "        if len(rec_pos): # array with a single element\n",
    "            hr += 1\n",
    "            arhr += 1. / (rec_pos[0]+1) # ranking starts from 1\n",
    "    \n",
    "    hr /= len(holdout)\n",
    "    arhr /= len(holdout)\n",
    "    return hr, arhr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate PureSVD(50):\n",
      "HR: 0.5346026490066225 ARHR: 0.2877945311678747\n"
     ]
    }
   ],
   "source": [
    "hr_puresvd, arhr_puresvd = evaluate(\n",
    "    train_matrix, test_items, item_factors, seed=rand_seed\n",
    ")\n",
    "print(f\"Hit Rate PureSVD({rank}):\\nHR: {hr_puresvd} ARHR: {arhr_puresvd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_matrix.nnz + len(test_items) == all_ratings.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check there's only 1 item per user\n",
    "assert len(test_items) == all_ratings.shape[0]\n",
    " # verify max rating of the test items\n",
    "assert (\n",
    "    ml_data\n",
    "    .groupby('userid')\n",
    "    .apply(lambda x:\n",
    "           x.loc[ # select item from test and its rating\n",
    "               x.movieid == all_items[test_items[all_users.get_loc(x.name)]],\n",
    "               'rating'\n",
    "           ] >= x.rating.max() # compare with max user rating\n",
    "          )\n",
    "    .all()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check test items are not present in train\n",
    "assert all([train_matrix[i, test_items[i]] == 0 for i in range(train_matrix.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify sampler function\n",
    "unobs = np.random.choice(1000, 500, replace=False)\n",
    "assert not np.in1d(sample_unseen(1000, 500, unobs), unobs).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-07 s\n",
       "\n",
       "Total time: 1.48792 s\n",
       "File: <ipython-input-12-16e187ae99f8>\n",
       "Function: evaluate at line 16\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    16                                           def evaluate(observations, holdout, item_factors,\n",
       "    17                                                        rand_size=999, topk=10, seed=None):\n",
       "    18                                               '''\n",
       "    19                                               Calculate Hit-Rate@topk with randomly sampled unseen items.\n",
       "    20                                               For further speedups can be wrapped by numba jit with minor changes.\n",
       "    21                                               Assumes only one test item per user.\n",
       "    22                                               '''\n",
       "    23         1     246172.0 246172.0      1.7      user_factors = observations.dot(item_factors)\n",
       "    24         1         58.0     58.0      0.0      n_users, n_items = train_matrix.shape\n",
       "    25         1          7.0      7.0      0.0      indptr = observations.indptr\n",
       "    26         1          6.0      6.0      0.0      indices = observations.indices\n",
       "    27                                               \n",
       "    28         1          5.0      5.0      0.0      hr = 0\n",
       "    29         1          5.0      5.0      0.0      arhr = 0\n",
       "    30         1        151.0    151.0      0.0      np.random.seed(seed) # control randomization\n",
       "    31      6041      49780.0      8.2      0.3      for i in range(len(indptr)-1):\n",
       "    32      6040      70877.0     11.7      0.5          head = indptr[i]\n",
       "    33      6040      69979.0     11.6      0.5          tail = indptr[i+1]\n",
       "    34                                                   \n",
       "    35      6040     526041.0     87.1      3.5          seen_items = np.concatenate(([holdout[i]], indices[head:tail]))\n",
       "    36      6040    6120088.0   1013.3     41.1          rand_items = sample_unseen(n_items, rand_size, seen_items)\n",
       "    37                                                   \n",
       "    38      6040     441198.0     73.0      3.0          holdout_prediction = item_factors[holdout[i], :] @ user_factors[i, :]\n",
       "    39      6040    4301728.0    712.2     28.9          random_predictions = item_factors[rand_items, :] @ user_factors[i, :]\n",
       "    40                                                   # test item goes first for simpler calculations:\n",
       "    41      6040     609605.0    100.9      4.1          merged_predictions = np.concatenate(([holdout_prediction], random_predictions))\n",
       "    42                                                   \n",
       "    43      6040    1621793.0    268.5     10.9          top_recs = topk_idx(merged_predictions, topk)\n",
       "    44      6040     441640.0     73.1      3.0          rec_pos, = np.where(top_recs == 0) # holdout item has index 0 (it was the first)\n",
       "    45      6040      59938.0      9.9      0.4          if len(rec_pos): # array with a single element\n",
       "    46      3229      29200.0      9.0      0.2              hr += 1\n",
       "    47      3229     290866.0     90.1      2.0              arhr += 1. / (rec_pos[0]+1) # ranking starts from 1\n",
       "    48                                               \n",
       "    49         1         15.0     15.0      0.0      hr /= len(holdout)\n",
       "    50         1         30.0     30.0      0.0      arhr /= len(holdout)\n",
       "    51         1          8.0      8.0      0.0      return hr, arhr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f evaluate evaluate(train_matrix, test_items, item_factors, seed=rand_seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:recwalk]",
   "language": "python",
   "name": "conda-env-recwalk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
