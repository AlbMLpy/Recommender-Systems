{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "from polara.datasets.movielens import get_movielens_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seed, rand_seed = 0, 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load row Data file\n",
    "\n",
    "DATA_NAME = 'ml-1m'\n",
    "DATA_FILE = 'D:/datasets/recsys/movielens/{}.zip'.format(DATA_NAME)\n",
    "\n",
    "ml_data = get_movielens_data(local_file=DATA_FILE, get_genres=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode users and items to [0, N] interval with no missing indices\n",
    "useridx, all_users = pd.factorize(ml_data.userid)\n",
    "itemidx, all_items = pd.factorize(ml_data.movieid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings = csr_matrix( # for efficient storage and some computations\n",
    "    (\n",
    "        ml_data.rating.values,\n",
    "        (useridx, itemidx)\n",
    "    )\n",
    ")\n",
    "all_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(matrix, seed=None):\n",
    "    '''\n",
    "    Uses CSR format to efficiently access non-zero elements.\n",
    "    Can be easily wrapped by numba jit with minor changes.\n",
    "    '''\n",
    "    test_items = []\n",
    "    indptr = matrix.indptr\n",
    "    indices = matrix.indices\n",
    "    data = matrix.data\n",
    "    np.random.seed(seed)\n",
    "    for i in range(len(indptr)-1): # for every user i\n",
    "        head = indptr[i]\n",
    "        tail = indptr[i+1]\n",
    "        vals = data[head:tail] # user ratings\n",
    "        pos_max, = np.where(vals == vals.max())\n",
    "        top_items = indices[head + pos_max]\n",
    "        test_items.append(np.random.choice(top_items))\n",
    "    return np.array(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = test_split(all_ratings, seed=split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = all_ratings.copy() # avoid mutating original data\n",
    "train_matrix[np.arange(len(test_items)), test_items] = 0 # exclude test items\n",
    "train_matrix.eliminate_zeros()\n",
    "train_matrix = (train_matrix > 0).astype('f8') # make data implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 50\n",
    "_, s, vh = svds(train_matrix, k=rank, return_singular_vectors='vh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50,), (50, 3706))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape, vh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s[::-1] # sort in decreasing order of singular values\n",
    "item_factors = vh[::-1, :].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_unseen(pool_size, sample_size, exclude):\n",
    "    '''Efficient sampling from a range with exclusion'''\n",
    "    assert (pool_size-len(exclude)) >= sample_size \n",
    "    src = np.random.rand(pool_size)\n",
    "    np.put(src, exclude, -1) # will never get to the top\n",
    "    return np.argpartition(src, -sample_size)[-sample_size:]\n",
    "\n",
    "def topk_idx(arr, topk, unsorted=False):\n",
    "    'Select top-k elements. Sort for raniking metrics.'\n",
    "    top_unsorted = np.argpartition(arr, -topk)[-topk:]\n",
    "    if unsorted:\n",
    "        return top_unsorted\n",
    "    return top_unsorted[np.argsort(-arr[top_unsorted])]\n",
    "\n",
    "\n",
    "def evaluate(observations, holdout, item_factors, rand_size=999, topk=10, seed=None):\n",
    "    '''\n",
    "    Calculate Hit-Rate@topk with randomly sampled unseen items.\n",
    "    For further speedups can be wrapped by numba jit with minor changes.\n",
    "    '''\n",
    "    n_users, n_items = train_matrix.shape\n",
    "    user_factors = observations.dot(item_factors)\n",
    "    indptr = observations.indptr\n",
    "    indices = observations.indices\n",
    "    \n",
    "    hr = 0\n",
    "    arhr = 0\n",
    "    for i in range(len(indptr)-1):\n",
    "        head = indptr[i]\n",
    "        tail = indptr[i+1]\n",
    "        \n",
    "        seen_items = np.r_[holdout[i], indices[head:tail]]\n",
    "        rand_items = sample_unseen(n_items, rand_size, seen_items)\n",
    "        \n",
    "        holdout_prediction = item_factors[holdout[i], :] @ user_factors[i, :]\n",
    "        random_predictions = item_factors[rand_items, :] @ user_factors[i, :]\n",
    "        merged_predictions = np.r_[holdout_prediction, random_predictions] # test item is first\n",
    "        \n",
    "        top_recs = topk_idx(merged_predictions, topk)\n",
    "        recs_pos, = np.where(top_recs == 0) # holdout item has index 0 (it was the first)\n",
    "        if len(recs_pos): # array with a single element\n",
    "            hr += 1\n",
    "            arhr += 1. / (recs_pos[0]+1) # ranking starts from 1\n",
    "    \n",
    "    hr /= len(holdout)\n",
    "    arhr /= len(holdout)\n",
    "    return hr, arhr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate PureSVD(50):\n",
      "HR: 0.5362582781456954 ARHR: 0.2862381083780081\n"
     ]
    }
   ],
   "source": [
    "hr_puresvd, arhr_puresvd = evaluate(train_matrix, test_items, item_factors, seed=rand_seed)\n",
    "print(f\"Hit Rate PureSVD({rank}):\\nHR: {hr_puresvd} ARHR: {arhr_puresvd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_matrix.nnz + len(test_items) == all_ratings.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check there's only 1 item per user\n",
    "assert len(test_items) == all_ratings.shape[0]\n",
    " # verify max rating of the test items\n",
    "assert (\n",
    "    ml_data\n",
    "    .groupby('userid')\n",
    "    .apply(lambda x:\n",
    "           x.loc[ # select item from test and its rating\n",
    "               x.movieid == all_items[test_items[all_users.get_loc(x.name)]],\n",
    "               'rating'\n",
    "           ] >= x.rating.max() # compare with max user rating\n",
    "          )\n",
    "    .all()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check test items are not present in train\n",
    "assert all([train_matrix[i, test_items[i]] == 0 for i in range(train_matrix.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify sampler function\n",
    "unobs = np.random.choice(1000, 500, replace=False)\n",
    "assert not np.in1d(sample_unseen(1000, 500, unobs), unobs).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-07 s\n",
       "\n",
       "Total time: 2.33417 s\n",
       "File: <ipython-input-12-df93d0691969>\n",
       "Function: evaluate at line 16\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    16                                           def evaluate(observations, holdout, item_factors, rand_size=999, topk=10, seed=None):\n",
       "    17                                               '''\n",
       "    18                                               Calculate Hit-Rate@topk with randomly sampled unseen items.\n",
       "    19                                               For further speedups can be wrapped by numba jit with minor changes.\n",
       "    20                                               '''\n",
       "    21         1        101.0    101.0      0.0      n_users, n_items = train_matrix.shape\n",
       "    22         1     296908.0 296908.0      1.3      user_factors = observations.dot(item_factors)\n",
       "    23         1         29.0     29.0      0.0      indptr = observations.indptr\n",
       "    24         1          7.0      7.0      0.0      indices = observations.indices\n",
       "    25                                               \n",
       "    26         1          5.0      5.0      0.0      hr = 0\n",
       "    27         1          5.0      5.0      0.0      arhr = 0\n",
       "    28      6041      53417.0      8.8      0.2      for i in range(len(indptr)-1):\n",
       "    29      6040      74583.0     12.3      0.3          head = indptr[i]\n",
       "    30      6040      73753.0     12.2      0.3          tail = indptr[i+1]\n",
       "    31                                                   \n",
       "    32      6040    3665274.0    606.8     15.7          seen_items = np.r_[holdout[i], indices[head:tail]]\n",
       "    33      6040    6528933.0   1080.9     28.0          rand_items = sample_unseen(n_items, rand_size, seen_items)\n",
       "    34                                                   \n",
       "    35      6040     463008.0     76.7      2.0          holdout_prediction = item_factors[holdout[i], :] @ user_factors[i, :]\n",
       "    36      6040    5588649.0    925.3     23.9          random_predictions = item_factors[rand_items, :] @ user_factors[i, :]\n",
       "    37      6040    3895162.0    644.9     16.7          merged_predictions = np.r_[holdout_prediction, random_predictions] # test item is first\n",
       "    38                                                   \n",
       "    39      6040    1781301.0    294.9      7.6          top_recs = topk_idx(merged_predictions, topk)\n",
       "    40      6040     504177.0     83.5      2.2          recs_pos, = np.where(top_recs == 0) # holdout item has index 0 (it was the first)\n",
       "    41      6040      70818.0     11.7      0.3          if len(recs_pos): # array with a single element\n",
       "    42      3224      30071.0      9.3      0.1              hr += 1\n",
       "    43      3224     315488.0     97.9      1.4              arhr += 1. / (recs_pos[0]+1) # ranking starts from 1\n",
       "    44                                               \n",
       "    45         1         15.0     15.0      0.0      hr /= len(holdout)\n",
       "    46         1         22.0     22.0      0.0      arhr /= len(holdout)\n",
       "    47         1          6.0      6.0      0.0      return hr, arhr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f evaluate evaluate(train_matrix, test_items, item_factors, seed=rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:recwalk]",
   "language": "python",
   "name": "conda-env-recwalk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
