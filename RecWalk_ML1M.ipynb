{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, diags, eye, block_diag, bmat\n",
    "from scipy.sparse.linalg import norm\n",
    "\n",
    "\n",
    "from utils import topk_idx, sample_unseen\n",
    "try:\n",
    "    from ipypb import track\n",
    "except ImportError:\n",
    "    from tqdm.auto import tqdm as track\n",
    "    \n",
    "from polara.datasets.movielens import get_movielens_data\n",
    "from dataprep import split_holdout, sample_unseen_interactions\n",
    "from utils import topk_idx, sample_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_seed, rand_seed = 0, 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load row Data file\n",
    "DATA_NAME = 'ml-1m'\n",
    "DATA_FILE = '../{}.zip'.format(DATA_NAME)\n",
    "\n",
    "ml_data = get_movielens_data(local_file=DATA_FILE, get_genres=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use sparse format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode users and items to [0, N] interval with no missing indices\n",
    "useridx, all_users = pd.factorize(ml_data.userid)\n",
    "itemidx, all_items = pd.factorize(ml_data.movieid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1000209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ratings = csr_matrix( # for efficient storage and some computations\n",
    "    (\n",
    "        ml_data.rating.values,\n",
    "        (useridx, itemidx)\n",
    "    )\n",
    ")\n",
    "all_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Mtx:\n",
      "Users: 6040;\n",
      "Items: 3706;\n",
      "NNZ entries: 1000209;\n",
      "Density: 4.468363%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Initial Mtx:\\nUsers: {};\\nItems: {};\\nNNZ entries: {};\\nDensity: {:%}\"\n",
    "    .format(\n",
    "        *all_ratings.shape,\n",
    "        all_ratings.nnz,\n",
    "        all_ratings.nnz / np.prod(all_ratings.shape)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(matrix, seed=None):\n",
    "    '''\n",
    "    Uses CSR format to efficiently access non-zero elements.\n",
    "    Can be easily wrapped by numba jit with minor changes.\n",
    "    '''\n",
    "    test_items = []\n",
    "    indptr = matrix.indptr\n",
    "    indices = matrix.indices\n",
    "    data = matrix.data\n",
    "    np.random.seed(seed) # control randomization\n",
    "    for i in range(len(indptr)-1): # for every user i\n",
    "        head = indptr[i]\n",
    "        tail = indptr[i+1]\n",
    "        vals = data[head:tail] # user ratings\n",
    "        pos_max, = np.where(vals == vals.max())\n",
    "        top_items = indices[head + pos_max] # top-rated items for user i\n",
    "        test_items.append(np.random.choice(top_items)) # sample of top-rated\n",
    "    return np.array(test_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items = test_split(all_ratings, seed=split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = all_ratings.copy() # avoid mutating original data\n",
    "train_matrix[np.arange(len(test_items)), test_items] = 0 # exclude test items\n",
    "train_matrix.eliminate_zeros()\n",
    "train_matrix = (train_matrix > 0).astype('f8') # make data implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 994169 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mtx:\n",
      "Users: 6040;\n",
      "Items: 3706;\n",
      "NNZ entries: 994169;\n",
      "Density: 4.441379%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Train Mtx:\\nUsers: {};\\nItems: {};\\nNNZ entries: {};\\nDensity: {:%}\"\n",
    "    .format(\n",
    "        *train_matrix.shape,\n",
    "        train_matrix.nnz,\n",
    "        train_matrix.nnz / np.prod(train_matrix.shape)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from SLIM import SLIM, SLIMatrix\n",
    "#Parameters on NN:\n",
    "n_items = train_matrix.shape[1]\n",
    "C = int(n_items * 0.1)\n",
    " #Train Matrix W:\n",
    "trainmat = SLIMatrix(train_matrix)\n",
    "params = {'algo':'cd',\n",
    "          'nthreads': 4,\n",
    "          'l1r': 10,\n",
    "          'l2r': 10,\n",
    "          'nnbrs': C\n",
    "         }\n",
    "model = SLIM()\n",
    "model.train(params, trainmat)\n",
    "#Got Matrix W:\n",
    "WSlim = model.to_csr()\n",
    "np.savez_compressed(\n",
    "    'W_model_SLIM_ML1M',\n",
    "    indices = WSlim.indices,\n",
    "    indptr = WSlim.indptr,\n",
    "    data = WSlim.data,\n",
    "    item_index = all_items\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3706x3706 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 113242 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WSlim_data = np.load('W_model_SLIM_ML1M.npz')\n",
    "WSlim = csr_matrix(\n",
    "    (WSlim_data['data'], WSlim_data['indices'], WSlim_data['indptr']),\n",
    "    shape = (len(WSlim_data['item_index']),)*2\n",
    ")\n",
    "np.testing.assert_array_equal(all_items, WSlim_data['item_index'])\n",
    "\n",
    "WSlim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density of W: 0.824511%\n",
      "Number of elements less than 0 in W: 0\n",
      "Maximal diagonal element of the W:   0.0\n"
     ]
    }
   ],
   "source": [
    "#Density of distance matrix W, diagonal and other elements\n",
    "print(f\"Density of W: {WSlim.nnz / np.prod(WSlim.shape):%}\")\n",
    "print(f\"Number of elements less than 0 in W: {(WSlim.data<0).sum()}\")\n",
    "print(f\"Maximal diagonal element of the W:   {WSlim.diagonal().max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecWalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make P matrix that our final recommendation model\n",
    "def rec_walk_model(item_model, rating_matrix, alpha=0.005):\n",
    "    inter_item = item_model / norm(item_model, np.inf)\n",
    "    adjustment = 1 - inter_item.sum(axis=1).A.squeeze() # stochasticity adjustment\n",
    "    inter_item += diags(adjustment, shape=item_model.shape, format='csr')\n",
    "\n",
    "    transition = block_diag( # M matrix\n",
    "        (eye(rating_matrix.shape[0], format='csr'), inter_item),\n",
    "        format = 'csr',\n",
    "        dtype = 'float64'\n",
    "    )\n",
    "    walk_model = bmat( # H matrix\n",
    "        [[None, rating_matrix], [rating_matrix.T, None]],\n",
    "        format = 'csr',\n",
    "        dtype = 'float64'\n",
    "    )\n",
    "    k = np.reciprocal(walk_model.sum(axis=1).A.squeeze())\n",
    "    walk_model = diags(k, format='csr').dot(walk_model)\n",
    "    return alpha * walk_model + (1-alpha) * transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RecWalk P matrix with W SLIM based:\n",
    "transition_matrix = rec_walk_model(WSlim, train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density of P: 2.222811%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Density of P: {transition_matrix.nnz/np.prod(transition_matrix.shape):%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(scores, holdout_items, holdout_unseen, topk=10):\n",
    "    rows = np.arange(len(holdout_items))\n",
    "    holdout_scores = scores[rows, holdout_items]\n",
    "    random_scores = scores[\n",
    "        np.broadcast_to(rows[:, None], holdout_unseen.shape),\n",
    "        holdout_unseen\n",
    "    ]\n",
    "    \n",
    "    test_scores = np.concatenate((holdout_scores[:, None], random_scores), axis=1)\n",
    "    top_recs = np.apply_along_axis(topk_idx, 1, test_scores, topk)        \n",
    "    _, rec_pos = np.where(top_recs == 0) # holdout has index 0 by construction\n",
    "    \n",
    "    hr = len(rec_pos) / len(holdout_items)\n",
    "    arhr = np.reciprocal(rec_pos + 1.).sum() / len(holdout_items)\n",
    "    return hr, arhr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a few more steps to future to capture intersactions between items:\n",
    "K = 20\n",
    "\n",
    "n_users = train_matrix.shape[0]\n",
    "k_step_matrix = transition_matrix[:n_users, :].toarray()\n",
    "transition_matrix = transition_matrix.tocsc()\n",
    "\n",
    "metrics = []\n",
    "for k in track(range(K)): \n",
    "    k_step_matrix = transition_matrix.T.dot(k_step_matrix.T).T\n",
    "    prediction_matrix = k_step_matrix[:, n_users:]\n",
    "    metrics.append(\n",
    "        evaluate(prediction_matrix, holdout_items, unseen_samples)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
